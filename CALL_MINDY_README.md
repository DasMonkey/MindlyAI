# ğŸ¤ Call Mindy - Voice AI Assistant

## Overview
**Call Mindy** is a real-time voice AI feature powered by Google's **Gemini 2.5 Flash Native Audio** model. It allows users to have natural voice conversations with AI about any webpage they're viewing.

## âœ¨ Features
- **Real-time Voice Conversation**: Talk to AI using your microphone and hear responses
- **Context-Aware**: AI understands the current page content automatically
- **Native Audio**: High-quality voice synthesis (24kHz)
- **Live Transcription**: See real-time text transcription of both user and AI speech
- **Interrupt Support**: Can interrupt AI mid-response to ask follow-up questions
- **Beautiful UI**: Purple gradient modal with status indicators

## ğŸ¯ Use Cases
1. **Tax Forms**: "Help me fill out question 1 about tax residency..."
2. **Legal Documents**: "What does this clause mean in simple terms?"
3. **Technical Documentation**: "Can you explain this API endpoint?"
4. **Research Papers**: "Summarize the key findings..."
5. **Shopping**: "Compare these product features..."

## ğŸ—ï¸ Architecture

### Files Created
```
Chrome-ext-GoogleAI/
â”œâ”€â”€ gemini-live-modal.html          # Modal UI structure
â”œâ”€â”€ gemini-live-modal.css           # Modal styling (gradient theme)
â”œâ”€â”€ gemini-live-connection.js       # WebSocket manager & modal controller
â””â”€â”€ audio-processor.js              # Audio capture & playback
```

### Technology Stack
- **Gemini Live API**: `gemini-2.5-flash-native-audio-preview-09-2025`
- **WebSocket**: Real-time bidirectional communication
- **Web Audio API**: Microphone capture and audio playback
- **AudioWorklet**: Real-time audio processing

### Audio Specifications
- **Input**: 16-bit PCM, 16kHz, mono (from microphone)
- **Output**: 16-bit PCM, 24kHz, mono (from Gemini)
- **Encoding**: Base64 for WebSocket transmission
- **Format**: Little-endian

## ğŸ”§ How It Works

### 1. User Clicks "Call Mindy"
```javascript
// Triggered from floating popup button
callMindy() -> MindyModal.open()
```

### 2. Initialize Connection
```
1. Request microphone permission
2. Extract page context (title + 10,000 chars of content)
3. Open modal UI with "Connecting..." status
4. Initialize AudioProcessor for mic capture
5. Connect WebSocket to Gemini Live API
```

### 3. Setup Message
```json
{
  "setup": {
    "model": "models/gemini-2.5-flash-native-audio-preview-09-2025",
    "generation_config": {
      "response_modalities": ["AUDIO"],
      "temperature": 0.7
    },
    "system_instruction": {
      "parts": [{
        "text": "You are Mindy... [page context included]"
      }]
    },
    "input_audio_transcription": {},
    "output_audio_transcription": {}
  }
}
```

### 4. Audio Pipeline

**Microphone â†’ Gemini**
```
Microphone (getUserMedia)
  â†“
AudioContext (16kHz)
  â†“
AudioWorklet (Float32 â†’ Int16)
  â†“
Base64 Encode
  â†“
WebSocket.send({ realtimeInput: { audio: {...} } })
  â†“
Gemini Live API
```

**Gemini â†’ Speaker**
```
Gemini Live API
  â†“
WebSocket.onmessage
  â†“
Base64 Decode â†’ Int16Array
  â†“
Int16 â†’ Float32 conversion
  â†“
AudioBuffer (24kHz)
  â†“
BufferSource â†’ AudioContext.destination
  â†“
Speaker
```

### 5. Transcription Display
```
serverContent.inputTranscription  â†’ "You" transcript bubble
serverContent.outputTranscription â†’ "Mindy" transcript bubble
```

## ğŸ¨ UI Components

### Modal Structure
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤ Call Mindy                    âœ•  â”‚ Header (draggable)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         âšª (pulsing)                â”‚ Status Indicator
â”‚       Listening...                  â”‚ (green = listening, orange = speaking)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  You: About question 1...           â”‚ Transcript Area
â”‚  Mindy: Question 1 asks about...    â”‚ (auto-scroll)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ğŸ¤ Mute]  [ğŸ“ End Call]          â”‚ Controls
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Powered by Gemini 2.5 Native Audio â”‚ Footer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual States
- **Connecting**: White pulsing circle
- **Listening**: Green glowing circle + "Listening..."
- **Speaking**: Orange glowing circle + "Mindy is speaking..."
- **Muted**: Red button with ğŸ”‡ icon

## ğŸ”‘ Key Features

### 1. Automatic Voice Activity Detection (VAD)
- Automatically detects when user starts/stops speaking
- No need to press buttons to talk
- Configurable sensitivity (using API defaults)

### 2. Context Management
- Sends page context as `system_instruction` (persistent)
- Supports up to ~1M tokens
- Extracts title, meta description, and first 10,000 chars

### 3. Interrupt Handling
```javascript
if (serverContent.interrupted) {
  audioProcessor.stopAudio(); // Stop AI speech immediately
}
```

### 4. Audio Quality
- Echo cancellation enabled
- Noise suppression enabled
- Auto gain control enabled
- 16kHz capture for optimal quality/bandwidth balance

## ğŸ§ª Testing Checklist

### Basic Functionality
- [ ] Click "Call Mindy" button
- [ ] Microphone permission granted
- [ ] Modal opens and connects
- [ ] Status changes to "Listening..."
- [ ] Speak a question
- [ ] User transcript appears
- [ ] AI responds with voice
- [ ] AI transcript appears
- [ ] Can mute/unmute
- [ ] Can end call

### Edge Cases
- [ ] Deny microphone permission â†’ Error message
- [ ] No API key â†’ Alert to set up key
- [ ] Close modal mid-conversation â†’ Cleanup properly
- [ ] Interrupt AI mid-response â†’ Audio stops
- [ ] Mute during speech â†’ Audio not sent
- [ ] Network disconnect â†’ Handle gracefully

### Performance
- [ ] Low latency (<500ms response time)
- [ ] No audio glitches or crackling
- [ ] Smooth visual state transitions
- [ ] Memory cleanup on close

## ğŸ› Troubleshooting

### "Microphone access denied"
- Browser blocked microphone access
- Check site permissions in browser settings
- Try HTTPS (required for getUserMedia)

### "Failed to connect"
- Check API key is valid
- Verify internet connection
- Check browser console for WebSocket errors

### "No audio output"
- Check system audio settings
- Verify speaker/headphone connection
- Check browser audio permissions

### "Choppy audio"
- Slow internet connection
- High CPU usage on device
- Try closing other tabs/apps

## ğŸš€ Future Enhancements

### Planned Features
1. **PDF Support**: Extract text from PDFs for context
2. **Multi-language**: Support conversations in different languages
3. **Function Calling**: Let AI perform actions (save notes, search, etc.)
4. **Session History**: Save and resume conversations
5. **Voice Selection**: Choose different AI voices
6. **Proactive Audio**: AI can ask clarifying questions

### API Features to Explore
- `proactive_audio`: AI ignores irrelevant audio
- `enable_affective_dialog`: AI adapts tone to user emotion
- Tool use: Function calling for actions
- Session resumption: Continue conversations later

## ğŸ“Š API Usage

### Costs (Approximate)
- **Input**: ~$0.01 per 1,000 audio seconds
- **Output**: ~$0.01 per 1,000 audio seconds
- **Context**: Included in system instruction (free up to limits)

### Rate Limits
- Check Google AI Studio for current limits
- Typically: 60 requests per minute
- Audio streaming counts as one session

## ğŸ” Security Notes

- API key stored in Chrome's local storage (encrypted by browser)
- WebSocket connection uses TLS (wss://)
- No audio data stored locally or remotely
- Page context sent only for current session
- Microphone access requires explicit user permission

## ğŸ“± Browser Compatibility

### Supported Browsers
- âœ… **Chrome**: Full support (v88+)
- âœ… **Edge**: Full support (Chromium-based)
- âš ï¸ **Firefox**: Partial (AudioWorklet support varies)
- âŒ **Safari**: Limited (WebSocket/AudioWorklet issues)

### Requirements
- HTTPS connection (for microphone access)
- Modern browser with WebSocket support
- AudioWorklet API support
- getUserMedia API support

## ğŸ“š Resources

- [Gemini Live API Docs](https://ai.google.dev/api/live)
- [WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [AudioWorklet](https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet)

---

**Built with â¤ï¸ using Gemini 2.5 Flash Native Audio (09-2025)**
